# -*- coding: utf-8 -*-
"""Background Extraction - Pixel KDE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PSdqhEXD4pu1pb4q0H6kPDXj1FdBlrpx

### **Import Packages**
"""

#Import Packages

## Basics 
try:
  import cupy as cp
except:
  print("Cupy not available!")
import numpy as np
import matplotlib.pyplot as plt
import gdown
import math
import random
import pandas as pd
from scipy import stats

## Computer Vision

import cv2
from IPython.display import Image 
from google.colab.patches import cv2_imshow
import torch

## Utilities

import os
import glob
import yaml
import time

"""## **Download Data & Arrange Frames**

### **Download Different Location / Gray Video**
"""

# Different Location / Gray Video

url = 'https://drive.google.com/u/0/uc?id=1NZ_70h3P8let_GmnAYnJKs9Dk5l8q2u9&export=download'
output = 'rabbit_video_full'
gdown.download(url, output, quiet=False)

"""### **Download Color Sample Video (2nd out of 5)**"""

# Download Sample Data (1st video)

url = 'https://drive.google.com/u/0/uc?id=1n0mUW_PNNL2siOhw2u_GORezTod8Ta8r&export=download'
output = 'rabbit_video_1'
gdown.download(url, output, quiet=False)

# Download Sample Data (2nd video)

url = 'https://drive.google.com/u/0/uc?id=1vZhU2yHF52aeO05s1Imb3DUYP696n-yC&export=download'
output = 'rabbit_video_2'
gdown.download(url, output, quiet=False)

# Download Sample Data (3rd Video)

url = 'https://drive.google.com/u/0/uc?id=1YTRqYfPxi3aEDZ7njoGbddafarOv5iC5&export=download'
output = 'rabbit_video_3'
gdown.download(url, output, quiet=False)

# Download Sample Data (4th Video)

url = 'https://drive.google.com/u/0/uc?id=1QjbdVAm2_dEGudOC9DZQZ5jqNKapv-MD&export=download'
output = 'rabbit_video_4'
gdown.download(url, output, quiet=False)

# Download Sample Data (5th video)

url = 'https://drive.google.com/u/0/uc?id=1ck36F4Ut5qAugo7q5LqQlh6WFETx5-7Q&export=download'
output = 'rabbit_video_5'
gdown.download(url, output, quiet=False)

"""## **Pixel-wise KDE and Statistics**

### **Functions**
"""

# Global Function - Background Extraction

## Extract Video Frames

def read_video_frames_numpy_arrays(vid, sample_frame_count = 15, grayscale = False):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ### Create empty Numpy Array 4D with UINT8 type
  if grayscale:
    video_np = np.empty((math.ceil(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))/sample_frame_count), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), 
                         int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))), np.dtype('uint8'))
  else:
    video_np = np.empty((math.ceil(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))/sample_frame_count), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), 
                         int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 3), np.dtype('uint8'))
  
  ### Create counters
  counter, counter_frames = 0, 0

  ### Loop the frames and save them in array
  success = True
  while success:
    success, image = cap.read()
    if success:
      if counter % sample_frame_count == 0:
        if grayscale:
          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        video_np[counter_frames] = image
        counter_frames += 1
      counter += 1

  print("Total execution time for extraction of frames:" , round((time.time()-start_time)), "seconds")
  return video_np

## Extract Video Frames - Multiple Video Array

def read_multiple_videos(vid_array, sample_frame_count = 15, flatten_bool = False):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ### Create empty Numpy Array 4D with UINT8 type

  video_np = None 
  #np.full((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))), 
  #                   fill_value = np.empty((1,), dtype= np.dtype('uint8')), dtype = np.dtype('object'))
  
  for vid in vid_array:
    cap = cv2.VideoCapture(vid)
    random_frames = np.random.randint(1, sample_frame_count, size=(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))

    video_np_temp = np.empty((np.count_nonzero(random_frames == 1), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), 
                              int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))), np.dtype('uint8'))
  
    ### Create counters
    counter, counter_frames = 0, 0

    ### Loop the frames and save them in array
    success = True
    while success:
      success, image = cap.read()
      if success and random_frames[counter] == 1 :
        video_np_temp[counter_frames] = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        counter_frames += 1
      counter += 1

    if flatten_bool:
      video_np_temp = get_video_np_flat(video_np_temp)
      if video_np is None:
        video_np = video_np_temp
      else:
        for element_index in range(video_np.shape[0]):
          video_np[element_index] = np.concatenate((video_np[element_index], video_np_temp[element_index]))
    else:
        if video_np is None:
          video_np = video_np_temp
        else:
          video_np = np.concatenate((video_np, video_np_temp), axis=0)
    
    del video_np_temp

  print("Total execution time for extraction of frames:" , round((time.time()-start_time)), "seconds")
  return video_np

## Get the Numpy arrays of each pixel across frames (temporal calculation)

def get_video_np_flat(arr):
  start_time = time.time()

  ### Create 1D array of Numpy arrays across the frames sequentially
  video_np_flat = np.empty((arr.shape[1]*arr.shape[2]), dtype=object)

  ### Create a counter to iterate
  counter = 0

  ### Loop columns and rows to save across frames
  for col_wise in range(arr.shape[1]):
    for row_wise in range(arr.shape[2]):
      video_np_flat[counter] = arr[:, col_wise, row_wise]
      counter += 1

  print("Total execution time for Numpy flattening:" , (time.time()-start_time), "seconds")
  return video_np_flat

## Get pixel densities for cross check

def get_pixel_density(arr, pixel_row, pixel_col):
  start_time = time.time()
  
  ### Plot pixel density 
  ax = pd.Series(arr[:, pixel_row, pixel_col]).plot.kde()
  
  print("Total execution time for pixel density estimation:" , (time.time()-start_time), "seconds")
  return arr[:, pixel_row, pixel_col]

## Calculate kurtosis graid for the mask

def get_kurtosis(arr):
  start_time = time.time()

  ### Create 1D array of Numpy array with float data type to store kurtosis values
  video_np_kurtosis = np.empty((arr.shape[0]), dtype = 'float64')

  ### Create a counter to iterate
  counter = 0

  ### Loop columns and rows to save across frames
  for array_element in arr:
    video_np_kurtosis[counter] = kurtosis(array_element)
    counter += 1

  print("Total execution time for kurtosis calculation:" , (time.time()-start_time), "seconds")
  return video_np_kurtosis 

def get_maximum_spike_KDE(arr):
  start_time = time.time()

  ### Create 1D array of Numpy array with float data type to store kurtosis values
  video_np_spike = np.empty((arr.shape[0]), dtype = 'float64')

  ### Create a counter to iterate
  counter = 0

  ### Loop columns and rows to save across frames
  for array_element in arr:
    hist, bin_edges = np.histogram(array_element, bins=20, density=True)
    video_np_spike[counter] = hist.max()
    counter += 1

  print("Total execution time for KDE spike calculation:" , (time.time()-start_time), "seconds")
  return video_np_spike 

########################################################################################################

# Pixel Density Values

## Parameters

local_maxima_threshold = 1e-04
linspace_grid_maximum = 300  ### investigate 255

## Functions

def get_pixel_density_values(arr, pixel_row, pixel_col, bandwidth = 'silverman', 
                             gridsize = 10, plot = False, verbose = True):
  
  ### Calculate and differentiate Gaussian KDE
  g_kde = stats.gaussian_kde(arr[:, pixel_row, pixel_col], bw_method = bandwidth)
  g_x = np.linspace(0, linspace_grid_maximum, gridsize) 
  g_kde_values = g_kde(g_x)
  local_maxima_points = (np.diff(np.sign(np.diff(g_kde_values))) < 0).nonzero()[0] + 1
  local_maxima_points_len = len(local_maxima_points)
  standard_deviation = np.std(arr[:, pixel_row, pixel_col])
  
  ### Eliminate small local maxima points 
  for local_maxima in local_maxima_points:
    if (g_kde_values[local_maxima] < local_maxima_threshold):
      local_maxima_points_len -= 1

  ### Plot pixel density 
  if plot:
    plt.plot(g_x, g_kde_values, label="scipy")
    plt.legend()
    plt.show()

  ### Verbose
  if verbose:
    print("\nFinal count of local maxima points:".ljust(35), local_maxima_points_len)
    print("Local maxima point indices:".ljust(35), local_maxima_points) 
    print("KDE values:".ljust(35), g_kde_values[local_maxima_points])
    print("Standard deviation:".ljust(35), standard_deviation, "\n")
  
  ### Return statement
  return local_maxima_points_len, standard_deviation

def get_pixel_density_values_efficient(arr, pixel_row, pixel_col, bandwidth = 'silverman', 
                             gridsize = 10, plot = False, verbose = True):
  
  ### Calculate and differentiate Gaussian KDE
  g_kde = stats.gaussian_kde(arr, bw_method = bandwidth)
  g_x = np.linspace(0, linspace_grid_maximum, gridsize) 
  g_kde_values = g_kde(g_x)
  local_maxima_points = (np.diff(np.sign(np.diff(g_kde_values))) < 0).nonzero()[0] + 1
  local_maxima_points_len = len(local_maxima_points)
  standard_deviation = np.std(arr)
  
  ### Eliminate small local maxima points 
  for local_maxima in local_maxima_points:
    if (g_kde_values[local_maxima] < local_maxima_threshold):
      local_maxima_points_len -= 1

  ### Plot pixel density 
  if plot:
    plt.plot(g_x, g_kde_values, label="scipy")
    plt.legend()
    plt.show()

  ### Verbose
  if verbose:
    print("\nFinal count of local maxima points:".ljust(35), local_maxima_points_len)
    print("Local maxima point indices:".ljust(35), local_maxima_points) 
    print("KDE values:".ljust(35), g_kde_values[local_maxima_points])
    print("Standard deviation:".ljust(35), standard_deviation, "\n")
  
  ### Return statement
  return local_maxima_points_len, standard_deviation

def get_distribution_frames(arr):
  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  frame_local_maxima = np.empty((arr.shape[1], arr.shape[2]), np.dtype('uint8'))
  frame_std = np.empty((arr.shape[1], arr.shape[2]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 
  for row in range(arr.shape[1]):
    for column in range(arr.shape[2]):
      frame_local_maxima[row, column], frame_std[row, column] = get_pixel_density_values(arr, row, column, gridsize= 15, verbose = False)

  ### Verbose
  print("Total execution time for pixel density estimation:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_local_maxima, frame_std

########################################################################################################

# RAM Efficient Functions 

##### GPU calculation - REDUNDANT

def get_std_efficient_cp(arr):
  start_time = time.time()

  ### Create a Cupy frame for stnadard deviation
  frame_std = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))
  
  ### Loop first two axis to extract standard deviation
  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):
      frame_std[row, column] = cp.std(cp.repeat(cp.arange(0,int(arr.shape[2])), arr[row, column].tolist()))
  
  ###Return statement & conversion to Numpy
  print("Total execution time for pixel standard deviations:", (time.time()-start_time), "seconds")    
  return cp.asnumpy(frame_std) 

def read_multiple_videos_efficient(vid_array, use_gpu = True, sample_frame_rate = 15):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  if use_gpu:
    
    ### Create empty Numpy Array 4D with UINT8 type
    video_cp = cp.zeros((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256), dtype='uint32')
    
    for vid in vid_array:
      cap = cv2.VideoCapture(vid)
      
      if sample_frame_rate is not None:
        random_frames = cp.random.randint(1, sample_frame_rate, size=(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))
      else:
        random_frames = cp.ones((int(cap.get(cv2.CAP_PROP_FRAME_COUNT))),)

      ### Create counter
      counter = 0

      if vid == 'rabbit_video_1':
        ### Loop the frames and save them in array
        success = True
        while success:
          success, image = cap.read()
          if success and random_frames[counter] == 1 and counter > 5000:
            video_cp[cp.arange(int(video_cp.shape[0])), cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
          counter += 1
          if counter % 10000 == 0:
            print('Video:', vid, '- Frame:', counter)
      else:
        ### Loop the frames and save them in array
        success = True
        while success:
          success, image = cap.read()
          if success and random_frames[counter] == 1 :
            video_cp[cp.arange(int(video_cp.shape[0])), cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
          counter += 1
          if counter % 10000 == 0:
            print('Video:', vid, '- Frame:', counter)

    #Return statements
    print("Total execution time for extraction of frames (RAM efficient - GPU):" , round((time.time()-start_time)), "seconds")
    return video_cp

  else:

    ### Create empty Numpy Array 4D with UINT8 type
    video_np = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256), dtype='uint32')
    
    for vid in vid_array:
      cap = cv2.VideoCapture(vid)
      
      if sample_frame_rate is not None:
        random_frames = np.random.randint(1, sample_frame_rate, size=(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))
      else:
        random_frames = np.ones((int(cap.get(cv2.CAP_PROP_FRAME_COUNT))),)

      ### Create counter
      counter = 0

      if vid == 'rabbit_video_1':
        ### Loop the frames and save them in array
        success = True
        while success:
          success, image = cap.read()
          if success and random_frames[counter] == 1 and counter > 5000:
            video_np[np.arange(int(video_np.shape[0])), cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
          counter += 1
          if counter % 10000 == 0:
            print('Video:', vid, '- Frame:', counter)
      else:
        ### Loop the frames and save them in array
        success = True
        while success:
          success, image = cap.read()
          if success and random_frames[counter] == 1 :
            video_np[np.arange(int(video_np.shape[0])), cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
          counter += 1
          if counter % 10000 == 0:
            print('Video:', vid, '- Frame:', counter)

    #Return statements
    print("Total execution time for extraction of frames (RAM efficient - No GPU):" , round((time.time()-start_time)), "seconds")
    return video_np
  
## KDE and Std calculation

def get_kde_efficient(arr, bandwidth, gridsize, random_sample_size):
  start_time = time.time()
  local_maxima_threshold = 1e-04

  ### Create empty frames for local maxima and standard deviation
  frame_local_maxima = np.empty((arr.shape[0], arr.shape[1]), np.dtype('uint8'))
  frame_std = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)
      g_kde_values = g_kde(np.linspace(0, 256, gridsize))
      local_maxima_points = (np.diff(np.sign(np.diff(g_kde_values))) < 0).nonzero()[0] + 1
      local_maxima_points_len = len(local_maxima_points)

      ### Eliminate small local maxima points 
      for local_maxima in local_maxima_points:
        if (g_kde_values[local_maxima] < local_maxima_threshold):
          local_maxima_points_len -= 1

      frame_local_maxima[row, column], frame_std[row, column] = local_maxima_points_len, np.std(repeat_np)
   
  ### Verbose
  print("Total execution time for pixel KDE:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_local_maxima, frame_std

################################################################################################################
### Mask and Background
################################################################################################################

## Get mask

def get_mask(mask_type, std_arr = None, kde_arr = None, tier1_threshold = 25, lower_threshold = 15, upper_threshold = 20):
  if (mask_type == 'std' and std_arr is not None):
    frame_std_temp = std_arr.copy()
    frame_std_temp[frame_std_temp > lower_threshold] = 255
    frame_std_temp[frame_std_temp <= lower_threshold] = 0
    print("Zero pixel count: ", len(np.where(frame_std_temp == 0)[0]))
    return frame_std_temp

  elif (mask_type == 'kde' and kde_arr is not None):
    frame_local_maxima_temp = kde_arr.copy()
    frame_local_maxima_temp[frame_local_maxima_temp > 1] = 255
    frame_local_maxima_temp[frame_local_maxima_temp <= 1] = 0
    print("Zero pixel count: ", len(np.where(frame_local_maxima_temp == 0)[0]))
    return frame_local_maxima_temp

  elif (mask_type == 'combined' and kde_arr is not None and std_arr is not None):
    
    combined_mask = np.zeros((480, 720), np.dtype('uint8'))
    for row in range(combined_mask.shape[0]):
      for column in range(combined_mask.shape[1]):
        if (std_arr[row, column] > tier1_threshold or kde_arr[row, column] > 2 or (kde_arr[row, column] > 1 and std_arr[row, column] > lower_threshold)):
          combined_mask[row, column] = 255
    print("Zero pixel count: ", len(np.where(combined_mask == 0)[0]))
    return combined_mask

  else:
    print('Please enter one of the following valid mask types: [std, kde, combined]')
    return None

## Get background image

def get_background_image(arr, mask):
  start_time = time.time()
  background_image = np.full((int(arr.shape[0]), int(arr.shape[1])), 255, np.dtype('uint8'))

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):
      if (mask is not None and mask[row, column] == 0) :
        background_image[row, column] = arr[row, column].argmax()
      if (mask is None):
        background_image[row, column] = arr[row, column].argmax()

  ### Return statements
  print("Total execution time for background image:", (time.time()-start_time), "seconds")    
  return background_image

## Peak curvature extraction

def get_peak_sharpness(arr, bandwidth = 'silverman', adj_constant = 30, random_sample_size = 2000):

  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  frame_peak = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)
      #peak = g_kde(np.linspace(0, 256, 256)).argmax()      
      g_kde_values = g_kde(np.linspace(arr[row, column].argmax() - adj_constant, arr[row, column].argmax() + adj_constant, 3))
      frame_peak[row, column] = np.diff(np.diff(g_kde_values))[0]
   
  ### Verbose
  print("Total execution time for KDE peakness:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_peak

## Peak standard deviation extraction

def get_peak_std(arr, bandwidth = 'silverman', adj_constant = 30, random_sample_size = 2000):

  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  frame_peak_std = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)      
      g_kde_values = g_kde(np.linspace(arr[row, column].argmax() - adj_constant, arr[row, column].argmax() + adj_constant, 10))
      frame_peak_std[row, column] = np.std(g_kde_values)
      
  ### Verbose
  print("Total execution time for KDE peak standard deviation:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_peak_std

def normalize_peak_std(arr):
  temp_arr = arr.copy()
  temp_arr[temp_arr > 0.03] = 0.03
  normalized_temp_arr = ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))
  return normalized_temp_arr

def normalize_peak_curvature(arr):
  
  ## Redundant conditions 
  #temp_arr[temp_arr > np.quantile(temp_arr, 0.95)] = np.quantile(temp_arr, 0.95)
  #temp_arr[temp_arr < np.quantile(temp_arr, 0.05)] = np.quantile(temp_arr, 0.05)
  
  temp_arr = arr.copy()
  temp_arr = np.abs(temp_arr)
  temp_arr[temp_arr > np.median(temp_arr)] = np.median(temp_arr)
  normalized_temp_arr = (temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr))
  return normalized_temp_arr

"""### **Reading Videos**"""

video_np = read_video_frames_numpy_arrays('rabbit_video_3', grayscale = True)

video_np_flat = get_video_np_flat(video_np)

video_multiple_np = read_multiple_videos(['rabbit_video_2', 'rabbit_video_3', 'rabbit_video_4'], sample_frame_count= 20)

video_multiple_cp_eff = read_multiple_videos_efficient(['rabbit_video_2', 'rabbit_video_3', 'rabbit_video_4'], sample_frame_rate = 3) 
video_multiple_cp_eff = video_multiple_cp_eff.reshape(480, 720, 256)
video_multiple_np_eff = cp.asnumpy(video_multiple_cp_eff)

frame_local_maxima, frame_std = get_kde_efficient(video_multiple_np_eff, bandwidth = 'silverman', gridsize = 15, random_sample_size = 10000)

mask = get_mask(mask_type = 'combined', std_arr = frame_std, kde_arr = frame_local_maxima, tier1_threshold = 25, lower_threshold = 20)
cv2_imshow(mask)

backgroumd_img = get_background_image(video_multiple_np_eff, mask)
cv2_imshow(backgroumd_img)

"""### **Visual Inspection of Pixel Units**"""

### Parameters

r, c = 307, 207

### Get function call
#print(frame_local_maxima[r,c])
get_pixel_density_values_efficient(np.repeat(np.arange(0, video_multiple_np_eff_all.shape[2]), video_multiple_np_eff_all[r, c].tolist()), r, c, gridsize = 15, bandwidth = 0.3, plot = True, verbose = True)

### Combined mask value in the mask
try:
  print('Combined mask value: '.ljust(35), mask[r,c])
except:
  print('Combined mask value: '.ljust(35), 'None')

frame_local_maxima, frame_std = get_distribution_frames(video_np)

frame_local_maxima, frame_std = get_distribution_frames_efficient_np(video_multiple_cp_eff)

"""### **Mask Operations**"""

# Combined mask - 3 Videos

lower_threshold = 15
upper_threshold = 20
combined_mask = np.zeros((480, 720), np.dtype('uint8'))

for row in range(combined_mask.shape[0]):
  for column in range(combined_mask.shape[1]):
    if (frame_local_maxima[row, column] > 1 and (frame_std[row, column] > lower_threshold)):
      combined_mask[row, column] = 255
    elif (frame_local_maxima[row, column] > 2):
      combined_mask[row, column] = 255
    elif (frame_std[row, column] > upper_threshold):
      combined_mask[row, column] = 255

print("Zero pixel count: ", len(np.where(combined_mask == 0)[0]))
cv2_imshow(combined_mask)

# Combined mask - Video #3

lower_threshold = 3
upper_threshold = 8
combined_mask = np.zeros((480, 720), np.dtype('uint8'))

for row in range(combined_mask.shape[0]):
  for column in range(combined_mask.shape[1]):
    if (frame_local_maxima[row, column] > 1 and (frame_std[row, column] > lower_threshold)):
      combined_mask[row, column] = 255
    elif (frame_local_maxima[row, column] > 2):
      combined_mask[row, column] = 255
    elif (frame_std[row, column] > upper_threshold):
      combined_mask[row, column] = 255

print("Zero pixel count: ", len(np.where(combined_mask == 0)[0]))
cv2_imshow(combined_mask)

# Standard deviation only mask

threshold = 15
frame_std_mask = frame_std.copy()
frame_std_mask[frame_std_mask > threshold] = 255
frame_std_mask[frame_std_mask <= threshold] = 0
print("Zero pixel count: ", len(np.where(frame_std_mask == 0)[0]))
cv2_imshow(frame_std_mask)

# Local maxima only mask

frame_local_maxima_mask = frame_local_maxima.copy()
frame_local_maxima_mask[frame_local_maxima_mask > 1] = 255
frame_local_maxima_mask[frame_local_maxima_mask <= 1] = 0
print("Zero pixel count: ", len(np.where(frame_local_maxima_mask == 0)[0]))
cv2_imshow(frame_local_maxima_mask)

# Combined mask

lower_threshold = 8
upper_threshold = 8
combined_mask = np.zeros((480, 720), np.dtype('uint8'))

for row in range(combined_mask.shape[0]):
  for column in range(combined_mask.shape[1]):
    if (frame_local_maxima[row, column] > 1 and (frame_std[row, column] > lower_threshold)):
      combined_mask[row, column] = 255
    elif (frame_local_maxima[row, column] > 2):
      combined_mask[row, column] = 255
    elif (frame_std[row, column] > upper_threshold):
      combined_mask[row, column] = 255

print("Zero pixel count: ", len(np.where(combined_mask == 0)[0]))
cv2_imshow(combined_mask)

"""### **Video 3 - Case**"""

video_multiple_cp_eff = read_multiple_videos_efficient(['rabbit_video_3'], sample_frame_rate = None) 
video_multiple_cp_eff = video_multiple_cp_eff.reshape(480, 720, 256)
video_multiple_np_eff_v3 = cp.asnumpy(video_multiple_cp_eff)

frame_local_maxima, frame_std = get_kde_efficient(video_multiple_np_eff_v3, bandwidth = 'silverman', gridsize = 15, random_sample_size = 5000)

mask = get_mask(mask_type = 'combined', std_arr = frame_std, kde_arr = frame_local_maxima, tier1_threshold = 15, lower_threshold = 8)
cv2_imshow(mask)

backgroumd_img = get_background_image(video_multiple_np_eff_v3, mask)
cv2_imshow(backgroumd_img)

"""### **Video 4 - Case**"""

video_multiple_cp_eff = read_multiple_videos_efficient(['rabbit_video_4'], sample_frame_rate = None) 
video_multiple_cp_eff = video_multiple_cp_eff.reshape(480, 720, 256)
video_multiple_np_eff_v4 = cp.asnumpy(video_multiple_cp_eff)

frame_local_maxima, frame_std = get_kde_efficient(video_multiple_np_eff_v4, bandwidth = 'silverman', gridsize = 15, random_sample_size = 5000)

mask = get_mask(mask_type = 'combined', std_arr = frame_std, kde_arr = frame_local_maxima, tier1_threshold = 8, lower_threshold = 6)
cv2_imshow(mask)

backgroumd_img = get_background_image(video_multiple_np_eff_v4, mask)
cv2_imshow(backgroumd_img)

backgroumd_img = get_background_image_full(video_multiple_np_eff_v4)
cv2_imshow(backgroumd_img)

frame_peak = get_peak_sharpness(video_multiple_np_eff_v4)
cv2_imshow(NormalizeData(frame_peak))

"""### **Read all videos & frames**"""

video_multiple_np_eff = read_multiple_videos_efficient(['rabbit_video_1', 'rabbit_video_2', 'rabbit_video_3', 
                                                        'rabbit_video_4', 'rabbit_video_5'], use_gpu = True, sample_frame_rate = None)

from google.colab import drive
drive.mount('/content/gdrive')

video_multiple_np_eff  = video_multiple_np_eff.reshape(480, 720, 256)

video_multiple_np_eff = cp.asnumpy(video_multiple_np_eff)
type(video_multiple_np_eff)

with open('/content/gdrive/My Drive/rabbit_video_eff.npy', 'wb') as f:
    np.save(f, video_multiple_np_eff)

with open('/content/gdrive/My Drive/rabbit_video_eff.npy', 'rb') as f:
    video_multiple_np_eff = np.load(f)

backgroumd_img = get_background_image(video_multiple_np_eff, mask = None)
cv2_imshow(backgroumd_img)

frame_std = get_peak_std(video_multiple_np_eff, adj_constant = 15, random_sample_size = 2000)

frame_peak = get_peak_sharpness(video_multiple_np_eff, adj_constant = 30, random_sample_size =5000)

prob = normalize_peak_std(frame_std)
cv2_imshow(prob * 255)

prob = normalize_peak_curvature(frame_peak)
cv2_imshow(prob * 255)

mask = get_mask(mask_type = 'combined', std_arr = frame_std, kde_arr = frame_local_maxima, tier1_threshold = 8, lower_threshold = 6)
cv2_imshow(mask)

with open('mask.npy', 'wb') as f:
    np.save(f, mask)

"""## **Heat Map**"""

with open('mask.npy', 'rb') as f:
    mask = np.load(f)

# Define function
def get_heat_map_binary(vid, mask, row_low = 50, row_high = 400, col_low = 100, col_high = 630):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros((row_high-row_low, col_high-col_low), np.dtype('uint32'))

  ## Create kernels
  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))

  ## Reading video frame by frame

  counter = 0
  success = True
  while success:
    success, image = cap.read()
    if success:

      ### convert each image to grayscale
      gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[row_low:row_high, col_low:col_high]
      thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
     
      ### Apply heatmap gaussian kernel
      
      opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

      ### Multiply with the mask values (make sure the type is uint8)
      masked_image = opening * (mask[row_low:row_high, col_low:col_high]/255).astype('uint8')

      ### Adjust the new created array
      frame_heat_map += (masked_image/255).astype('uint32')

  ## adjust the colorscale (red) + merge with extracted backgound ?

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map/int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) 

heat_map_binary = get_heat_map_binary('rabbit_video_4', mask = mask)
heat_map_binary

def normalize_heat_map(arr):
  temp_arr = arr.copy()
  return ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))

cv2_imshow(normalize_heat_map(heat_map_binary)*255)

rgba = cv2.cvtColor(np.full((350, 530, 3), (255,255,0), np.dtype('uint8')), cv2.COLOR_RGB2RGBA)
rgba[:,:,3] = normalize_heat_map(heat_map_binary)*255
cv2_imshow(rgba)

def blend_heatmap(background_image, heat_map, threshold = None):

  # Create RGB and alpha channels
  foreground = np.full((heat_map.shape[0], heat_map.shape[1], 3), (255,255,0), np.dtype('uint8')).astype(float)
  background = cv2.cvtColor(cv2.imread(background_image, cv2.IMREAD_GRAYSCALE), cv2.COLOR_GRAY2RGB)[50:400, 100:630].astype(float)
  alpha = normalize_heat_map(heat_map).astype(float)

  # Remove errors
  if threshold is not None:
    alpha[alpha > threshold] = 0 
  
  # Broadcast the alpha channel to third dimension
  alpha = np.stack((alpha,alpha,alpha), -1)

  # Blend with alpha channel
  foreground = cv2.multiply(alpha, foreground)
  background = cv2.multiply(1.0 - alpha, background)
  out_image = cv2.add(foreground, background)
  
  #Return statement
  return out_image

cv2_imshow(blend_heatmap('cage_background.png', heat_map_binary))

# Define function
def get_heat_map_binary_threshold(vid_array, mask, row_low = 50, row_high = 400, col_low = 100, col_high = 630):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros((row_high-row_low, col_high-col_low), np.dtype('uint32'))
  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))

  for vid in vid_array:
  ## Reading video frame by frame
    cap = cv2.VideoCapture(vid)
    counter = 0

    if vid == 'rabbit_video_1':
      success = True
      while success:
        success, image = cap.read()
        if success and counter > 5000:

          ### convert each image to grayscale
          gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
          thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
          opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

          ### Threshold and mask
          masked_image = (opening[row_low:row_high, col_low:col_high] * (mask[row_low:row_high, col_low:col_high]/255)).astype('uint8')

          ### Adjust the new created array
          frame_heat_map += (masked_image/255).astype('uint32')

        counter += 1
    else:
      success = True
      while success:
        success, image = cap.read()
        if success:

          ### convert each image to grayscale
          gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
          thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
          opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

          ### Threshold and mask
          masked_image = (opening[row_low:row_high, col_low:col_high] * (mask[row_low:row_high, col_low:col_high]/255)).astype('uint8')

          ### Adjust the new created array
          frame_heat_map += (masked_image/255).astype('uint32')

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map/(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)*len(vid_array))) 

def normalize_heat_map(arr):
  temp_arr = arr.copy()
  return ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))

def blend_heatmap(background_image, heat_map, threshold = None):

  # Create RGB and alpha channels
  foreground = np.full((heat_map.shape[0], heat_map.shape[1], 3), (255,255,0), np.dtype('uint8')).astype(float)
  background = cv2.cvtColor(cv2.imread(background_image, cv2.IMREAD_GRAYSCALE), cv2.COLOR_GRAY2RGB)[50:400, 100:630].astype(float)
  alpha = normalize_heat_map(heat_map).astype(float)

  # Remove errors
  if threshold is not None:
    alpha[alpha > threshold] = 0 
  
  # Broadcast the alpha channel to third dimension
  alpha = np.stack((alpha,alpha,alpha), -1)

  # Blend with alpha channel
  foreground = cv2.multiply(alpha, foreground)
  background = cv2.multiply(1.0 - alpha, background)
  out_image = cv2.add(foreground, background)
  
  #Return statement
  return out_image

heat_map_binary_thres_kernel_all = get_heat_map_binary_threshold(['rabbit_video_1', 'rabbit_video_2', 'rabbit_video_3', 'rabbit_video_4', 'rabbit_video_5'], mask = mask)
cv2_imshow(normalize_heat_map(heat_map_binary_thres_kernel_all)*255)

rgba = cv2.cvtColor(np.full((350, 530, 3), (255,255,0), np.dtype('uint8')), cv2.COLOR_RGB2RGBA)
rgba[:,:,3] = normalize_heat_map(heat_map_binary_thres_kernel_all)*255
cv2_imshow(rgba)
cv2_imshow(blend_heatmap('cage_background.png', heat_map_binary_thres_kernel_all, threshold = 0.99))

"""## **Video Material 2**"""

# Functions

def read_experiment_2_videos(vid_array, sample_frame_rate = 15, stop_frame = None, crop_parameters = None):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ### Create empty Numpy Array 2D with UINT32 type
  if crop_parameters is None:
    video_np = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256), dtype='uint32')
  else:
    video_np = np.zeros(((crop_parameters[1]-crop_parameters[0]) * (crop_parameters[3]-crop_parameters[2]), 256), dtype='uint32')

  for vid in vid_array:
    cap = cv2.VideoCapture(vid)
    
    if sample_frame_rate is not None:
      random_frames = np.random.randint(1, sample_frame_rate, size=(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))
    else:
      random_frames = np.ones((int(cap.get(cv2.CAP_PROP_FRAME_COUNT))),)

    ### Create counter
    counter = 0

    ### Loop the frames and save them in array
    success = True
    while success:
      success, image = cap.read()
      if success and random_frames[counter] == 1:
        if crop_parameters is None:
          cv2.imwrite('frame'+ str(counter)+ '.jpg', image)
          video_np[np.arange(int(video_np.shape[0])), cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
        else:
          video_np[np.arange(int(video_np.shape[0])), 
                   cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[crop_parameters[0]:crop_parameters[1], crop_parameters[2]:crop_parameters[3]].flatten()] += 1
      counter += 1
      if stop_frame is not None and counter > stop_frame:
        success = False
      if counter % 5000 == 0:
          print('Video:', vid, '- Frame:', counter)

    #Return statements
    print("Total execution time for extraction of frames (RAM efficient - No GPU):" , round((time.time()-start_time)), "seconds")
    return video_np.reshape(crop_parameters[1]-crop_parameters[0], crop_parameters[3]-crop_parameters[2], 256)

frame_crop = cv2.imread('frame57.jpg', cv2.IMREAD_GRAYSCALE)[195:440, 160:565]
cv2_imshow(frame_crop)

video_experiment_2_eff = read_experiment_2_videos(['rabbit_video_full'], sample_frame_rate = None, stop_frame = None, crop_parameters = [195, 440, 160, 565])

def pixel_std(arr):

  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  frame_std = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      frame_std[row, column] = np.std(repeat_np)
      
  ### Verbose
  print("Total execution time for standard deviation:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_std

frame_std = pixel_std(video_experiment_2_eff)

def get_peak_sharpness(arr, bandwidth = 'silverman', adj_constant = 30, random_sample_size = 2000):

  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  frame_peak = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)
      g_kde_values = g_kde(np.linspace(arr[row, column].argmax() - adj_constant, arr[row, column].argmax() + adj_constant, 3))
      frame_peak[row, column] = np.diff(np.diff(g_kde_values))[0]
   
  ### Verbose
  print("Total execution time for KDE peakness:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return frame_peak

frame_peak = get_peak_sharpness(video_experiment_2_eff)

def get_cage_mask_experiment_2(arr, frame_std, peak):
  mask = np.full((arr.shape[0], arr.shape[1]), 255, dtype = 'uint8')
  peak = np.abs(peak)
  arr = arr.argmax(axis=2)
  mask[np.logical_and(np.logical_and((arr > 130), (frame_std <= 25)), (peak > 0.01))] = 0
  mask[np.logical_and(np.logical_or((peak < 0.035), (frame_std > 20)), (arr <= 160))] = 255
  cv2_imshow(mask)
  return mask


mask_experiment_2 = get_cage_mask_experiment_2(video_experiment_2_eff, frame_std, frame_peak)

with open('mask_experiement_2.npy', 'wb') as f:
  np.save(f, mask_experiment_2)

with open('mask_experiement_2.npy', 'rb') as f:
  mask_experiment_2 = np.load(f)

def get_heat_map_experiment_2(vid, mask, crop_parameters):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros(((crop_parameters[1]-crop_parameters[0]), (crop_parameters[3]-crop_parameters[2])), np.dtype('uint32'))

  ## Create kernels
  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))

  ## Reading video frame by frame

  counter = 0
  success = True
  while success:
    success, image = cap.read()
    if success:

      ### convert each image to grayscale
      gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[crop_parameters[0]:crop_parameters[1], crop_parameters[2]:crop_parameters[3]]
      thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
     
      ### Apply heatmap gaussian kernel
      
      #opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

      ### Multiply with the mask values (make sure the type is uint8)
      masked_image = bw_img * (mask/255).astype('uint8')

      ### Adjust the new created array
      frame_heat_map += (masked_image/255).astype('uint32')

  ## adjust the colorscale (red) + merge with extracted backgound ?

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map/int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) 

heat_map_experiment_2 = get_heat_map_experiment_2('rabbit_video_full', mask = mask_experiment_2, crop_parameters = [195, 440, 160, 565])

def get_heat_map_experiment_2_EXP(vid, mask, crop_parameters, stop_frame):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros(((crop_parameters[1]-crop_parameters[0]), (crop_parameters[3]-crop_parameters[2])), np.dtype('uint32'))

  ## Create kernels
  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))

  ## Reading video frame by frame

  counter = 0
  success = True
  while success:
    success, image = cap.read()
    if success:

      ### convert each image to grayscale
      gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[crop_parameters[0]:crop_parameters[1], crop_parameters[2]:crop_parameters[3]]
      thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)      

      ### Multiply with the mask values (make sure the type is uint8)
      masked_image = bw_img * (mask/255).astype('uint8')

      ### Adjust the new created array
      frame_heat_map += (masked_image/255).astype('uint32')

      if counter == stop_frame:
        cv2_imshow(image)
        cv2_imshow(bw_img)
        cv2_imshow(masked_image)
        break
    counter += 1
        
  ## adjust the colorscale (red) + merge with extracted backgound ?

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return None

get_heat_map_experiment_2_EXP('rabbit_video_full', mask_experiment_2, [195, 440, 160, 565], 5)

def normalize_heat_map(arr):
  temp_arr = arr.copy()
  return ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))

def blend_heatmap(background_image, heat_map, threshold = None):

  # Create RGB and alpha channels
  foreground = np.full((heat_map.shape[0], heat_map.shape[1], 3), (255,255,0), np.dtype('uint8')).astype(float)
  background = cv2.cvtColor(cv2.imread(background_image, cv2.IMREAD_GRAYSCALE), cv2.COLOR_GRAY2RGB).astype(float)
  alpha = normalize_heat_map(heat_map).astype(float)

  # Remove errors
  if threshold is not None:
    alpha[alpha > threshold] = 0 
  
  # Broadcast the alpha channel to third dimension
  alpha = np.stack((alpha,alpha,alpha), -1)

  # Blend with alpha channel
  foreground = cv2.multiply(alpha, foreground)
  background = cv2.multiply(1.0 - alpha, background)
  out_image = cv2.add(foreground, background)
  
  #Return statement
  return out_image

cv2_imshow(normalize_heat_map(heat_map_experiment_2)*255)

rgba = cv2.cvtColor(np.full((heat_map_experiment_2.shape[0], heat_map_experiment_2.shape[1], 3), (0,0,255), np.dtype('uint8')), cv2.COLOR_RGB2RGBA)
rgba[:,:,3] = normalize_heat_map(heat_map_experiment_2)*255
cv2_imshow(rgba)
#cv2_imshow(blend_heatmap('experiment_2_cage.png', heat_map_experiment_2, threshold = 0.99))

### Hourly heatmap (every 10 minutes)

def get_heat_map_start_stop(vid, mask, crop_parameters, start_frame, stop_frame):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros(((crop_parameters[1]-crop_parameters[0]), (crop_parameters[3]-crop_parameters[2])), np.dtype('uint32'))

  ## Reading video frame by frame

  counter = 0
  success = True
  while success:
    success, image = cap.read()
    if success and (counter >= start_frame):
      ### convert each image to grayscale
      gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[crop_parameters[0]:crop_parameters[1], crop_parameters[2]:crop_parameters[3]]
      thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)      

      ### Multiply with the mask values (make sure the type is uint8)
      masked_image = bw_img * (mask/255).astype('uint8')

      ### Adjust the new created array
      frame_heat_map += (masked_image/255).astype('uint32')
    
    if (counter == stop_frame):
      success = False
    counter += 1
        
  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map

def normalize_heat_map(arr):
  temp_arr = arr.copy()
  return ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))

for i in range(6):
  print("Heatmap between ", str(i*10), " and ", str((i+1)*10), " minutes \n")
  heat_map_temp = get_heat_map_start_stop(vid = 'rabbit_video_full', mask = mask_experiment_2, crop_parameters = [195, 440, 160, 565], start_frame = (i*15000), stop_frame = ((i+1)*15000))
  cv2_imshow(normalize_heat_map(heat_map_temp)*255)

get_heat_map_start_stop('rabbit_video_full', mask_experiment_2, [195, 440, 160, 565], 0 * 15000, (0+1) * 15000)

mask_experiment_2

"""## **KDE Background Extractor**

### **Read Highway Video**
"""

video_road_survelliance = read_multiple_videos_efficient(['road_video_480.mp4'], use_gpu = False, sample_frame_rate = None)

video_road_survelliance  = video_road_survelliance.reshape(480, 854, 256)

"""### **MOG2 - Highway Video**"""

backSub = cv2.createBackgroundSubtractorMOG2()
cap = cv2.VideoCapture('road_video_480.mp4')
counter_frame = 1

success = True
while success:
  success, image = cap.read()

  if success:
    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    fgMask = backSub.apply(gray_img)
  
  if counter_frame % 10000 == 0:
    print("Frame", counter_frame, 'processed!')
  counter_frame += 1

cv2_imshow(backSub.getBackgroundImage())

cv2_imshow(cv2.subtract(cv2.cvtColor(frame250, cv2.COLOR_BGR2GRAY), backSub.getBackgroundImage()))

"""### **KNN - Highway Video**"""

# KNN

backSub = cv2.createBackgroundSubtractorKNN()
cap = cv2.VideoCapture('road_video_480.mp4')
counter_frame = 1

success = True
while success:
  success, image = cap.read()

  if success:
    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    fgMask = backSub.apply(gray_img)
  
cv2_imshow(backSub.getBackgroundImage())

cv2_imshow(cv2.subtract(cv2.cvtColor(frame250, cv2.COLOR_BGR2GRAY), backSub.getBackgroundImage()))

"""### **KDE (Our Approach) - Highway Video**"""

def read_video_efficient_KDE(vid):
  start_time = time.time()
  cap = cv2.VideoCapture(vid)

  ### Create empty Numpy Array 2D with UINT8 type
  video_np = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256), dtype='uint32')
  numpy_arange_vid_shape = np.arange(int(video_np.shape[0]))

  ### Create counter
  counter = 0

  ### Loop the frames and save them in array
  success = True
  while success:
    success, image = cap.read()
    if success and (random.randint(1,10) % 10 == 0):
      video_np[numpy_arange_vid_shape, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1
    counter += 1
    if counter % 100 == 0:
      print('Video:', vid, '- Frame:', counter, '- Time:', round((time.time()-start_time)))

  #Return statements
  print("Total execution time for extraction of frames (RAM efficient - No GPU):" , round((time.time()-start_time)), "seconds")
  return video_np.reshape((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256))

road_eff = read_video_efficient_KDE('road_video_480.mp4')

def get_efficient_array(vid_array):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ### Create empty Numpy Array 4D with UINT8 type
  video_np = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 256), dtype='uint32')
  
  for vid in vid_array:
    cap = cv2.VideoCapture(vid)

    ### Create counter & constants
    video_arrange_arr = np.arange(int(video_np.shape[0]))

    ### Loop the frames and save them in array
    success = True
    while success:
      success, image = cap.read()
      if success:
        video_np[video_arrange_arr, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1

  #Return statements
  print("Total execution time for extraction of frames (RAM efficient - No GPU):" , round((time.time()-start_time)), "seconds")
  return video_np

def get_background_image_KDE(arr, bandwidth = 'silverman', random_sample_size = 5000):
  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  background_img = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)      
      background_img[row, column] = g_kde(np.linspace(0, 255, 255)).argmax()
      
  ### Verbose
  print("Total execution time for KDE peak standard deviation:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return background_img

road_eff = get_efficient_array(['road_video_480.mp4'])
road_eff  = road_eff.reshape(480, 854, 256)

background_img_KDE = get_background_image_KDE(road_eff, random_sample_size = 150)

background_img_KDE = get_background_image_KDE(road_eff, random_sample_size = 150)

cv2_imshow(background_img_KDE)

cv2_imshow(cv2.cvtColor(frame250, cv2.COLOR_BGR2GRAY)*1.00 - background_img_KDE)

"""## **Development Area**"""

def read_benchmark_data(folder_name, train_image_max, img_size_tuple):
  start_time = time.time()

  ### Create empty Numpy Array 4D with UINT8 type
  video_np = np.zeros(((img_size_tuple[0] * img_size_tuple[1]), 256), dtype='uint32')
  video_arrange_arr = np.arange(int(video_np.shape[0]))

  os.chdir(folder_name)
  for file in glob.glob("b*.bmp"):
    if int(file[3:6]) <= train_image_max:
      image = cv2.imread("/content/images/" + file)
      video_np[video_arrange_arr, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).flatten()] += 1

  #Return statements
  print("Total execution time for extraction of frames (RAM efficient - No GPU):" , round((time.time()-start_time)), "seconds")
  return video_np.reshape(img_size_tuple[0], img_size_tuple[1], 256)

benchmark_camouflage = read_benchmark_data("/content/images/", 200, (120, 160))

def get_background_image_KDE(arr, bandwidth = 'silverman', random_sample_size = 5000):
  start_time = time.time()

  ### Create empty frames for local maxima and standard deviation
  background_img = np.empty((arr.shape[0], arr.shape[1]), np.dtype('float64'))

  ### Iterate each pixel to calculate density values 

  for row in range(arr.shape[0]):
    for column in range(arr.shape[1]):

      ### Calculate and differentiate Gaussian KDE
      repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
      g_kde = stats.gaussian_kde(np.random.choice(repeat_np, random_sample_size), bw_method = bandwidth)      
      background_img[row, column] = g_kde(np.linspace(0, 255, 255)).argmax()
      
  ### Verbose
  print("Total execution time for KDE peak standard deviation:", (time.time()-start_time), "seconds")    

  ### Return statement 
  return background_img

back_image = get_background_image_KDE(benchmark_camouflage, random_sample_size = 100)

benchmark_camouflage[0,0]

def get_point_KDE(arr, row, column, value, bandwidth = 0.1):

  repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
  g_kde = stats.gaussian_kde(repeat_np, bw_method = bandwidth)      
  return g_kde.evaluate(value)

get_point_KDE(benchmark_camouflage, 0, 0, 40)

cv2_imshow(back_image)

cv2_imshow(cv2.cvtColor(cv2.imread("/content/images/b00251.bmp"), cv2.COLOR_BGR2GRAY))

def foreground_extractor(arr, frame, threshold):
  segmented_img = np.empty((arr.shape[0], arr.shape[1]), np.dtype('uint8'))
  for i in range(arr.shape[0]):
    for j in range(arr.shape[1]):
      if (get_point_KDE(arr, i, j, frame[i,j]) > threshold):
        segmented_img[i,j] = 0
      else:
        segmented_img[i,j] = 255
  return segmented_img

img = foreground_extractor(arr = benchmark_camouflage, frame = cv2.cvtColor(cv2.imread("/content/images/b00251.bmp"), cv2.COLOR_BGR2GRAY), threshold = 0.01)
cv2_imshow(img)

img = foreground_extractor(back_image = back_image, frame = cv2.cvtColor(cv2.imread("/content/images/b00251.bmp"), cv2.COLOR_BGR2GRAY), threshold = 15)
cv2_imshow(img)

import glob, os

os.chdir("/content/images")
for file in glob.glob("b*.bmp"):
    if int(file[3:6]) <= 200: 
      break

print(cv2.imread("/content/images/b00049.bmp").shape)

arr = video_multiple_np_eff
gridsize = 15
row, column = 167, 368

repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
g_kde = stats.gaussian_kde(np.random.choice(repeat_np, 2000), bw_method = 'silverman')
peak = g_kde(np.linspace(0, 256, 256)).argmax()
g_kde_values = g_kde(np.linspace(peak-30, peak+30, 3))
local_maxima_points = (np.diff(np.diff(g_kde_values)))
print(arr[row, column].argmax())
print(peak)
print(local_maxima_points)
### Plot pixel density 
plt.plot(np.linspace(peak-30, peak+30, 3), g_kde_values, label="scipy") 
plt.plot(np.linspace(0, 256, 256), g_kde(np.linspace(0, 256, 256)), label="e")

plt.legend()
plt.show()

row, column = 132, 581
arr = video_road_survelliance.copy()
repeat_np = np.repeat(np.arange(0, arr.shape[2]), arr[row, column].tolist())
g_kde = stats.gaussian_kde(np.random.choice(repeat_np, 200), bw_method = 'silverman')
peak = g_kde(np.linspace(0, 255, 255)).argmax()
print(peak)
print(video_road_survelliance[row, column].argmax())

### Parameters

r, c = 142, 391

### Get function call
#print(frame_local_maxima[r,c])
get_pixel_density_values_efficient(np.repeat(np.arange(0, video_road_survelliance.shape[2]), video_road_survelliance[r, c].tolist()), r, c, gridsize = 15, bandwidth = 0.3, plot = True, verbose = True)

### Combined mask value in the mask
try:
  print('Combined mask value: '.ljust(35), mask[r,c])
except:
  print('Combined mask value: '.ljust(35), 'None')

cap = cv2.VideoCapture('road_video_480.mp4')

counter = 0
success = True
while success:
  success, image = cap.read()
  if success and counter == 250:
    cv2.imwrite('frame' + str(counter) + '.jpg', cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))
    success = False
  counter += 1

frame250 = cv2.imread('frame250.jpg')
frame250.mean()

### Adjust brightness

background_img_KDE_bright = background_img_KDE.copy() 
background_img_KDE_bright *= 1.02
cv2_imshow(background_img_KDE_bright)
print(background_img_KDE_bright.mean())

frame_random = cv2.imread('frame82750.jpg', cv2.IMREAD_GRAYSCALE)
cv2_imshow(frame_random)

kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 1))
thresh, bw_img = cv2.threshold(frame_random, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)


threshold = 150
frame_random[frame_random>threshold]  = 255
frame_random[frame_random<=threshold] = 0
cv2_imshow(opening)

# Define function
def get_heat_map_binary_threshold(vid_array, mask, row_low = 50, row_high = 400, col_low = 100, col_high = 630):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros((row_high-row_low, col_high-col_low), np.dtype('uint32'))
  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))

  for vid in vid_array:
  ## Reading video frame by frame
    cap = cv2.VideoCapture(vid)
    counter = 0

    if vid == 'rabbit_video_1':
      success = True
      while success:
        success, image = cap.read()
        if success and counter > 5000:

          ### convert each image to grayscale
          gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
          thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
          opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

          ### Threshold and mask
          masked_image = (opening[row_low:row_high, col_low:col_high] * (mask[row_low:row_high, col_low:col_high]/255)).astype('uint8')

          ### Adjust the new created array
          frame_heat_map += (masked_image/255).astype('uint32')

        counter += 1
    else:
      success = True
      while success:
        success, image = cap.read()
        if success:

          ### convert each image to grayscale
          gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
          thresh, bw_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
          opening = cv2.morphologyEx(bw_img, cv2.MORPH_OPEN, kernel)

          ### Threshold and mask
          masked_image = (opening[row_low:row_high, col_low:col_high] * (mask[row_low:row_high, col_low:col_high]/255)).astype('uint8')

          ### Adjust the new created array
          frame_heat_map += (masked_image/255).astype('uint32')

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map/(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)*len(vid_array))) 

heat_map_binary_thres_kernel_all = get_heat_map_binary_threshold(['rabbit_video_1', 'rabbit_video_2', 'rabbit_video_3', 'rabbit_video_4', 'rabbit_video_5'], mask = mask)

def normalize_heat_map(arr):
  temp_arr = arr.copy()
  return ((temp_arr - np.min(temp_arr)) / (np.max(temp_arr) - np.min(temp_arr)))

cv2_imshow(normalize_heat_map(heat_map_binary_thres_kernel_all)*255)

def blend_heatmap(background_image, heat_map, threshold = None):

  # Create RGB and alpha channels
  foreground = np.full((heat_map.shape[0], heat_map.shape[1], 3), (255,255,0), np.dtype('uint8')).astype(float)
  background = cv2.cvtColor(cv2.imread(background_image, cv2.IMREAD_GRAYSCALE), cv2.COLOR_GRAY2RGB)[50:400, 100:630].astype(float)
  alpha = normalize_heat_map(heat_map).astype(float)

  # Remove errors
  if threshold is not None:
    alpha[alpha > threshold] = 0 
  
  # Broadcast the alpha channel to third dimension
  alpha = np.stack((alpha,alpha,alpha), -1)

  # Blend with alpha channel
  foreground = cv2.multiply(alpha, foreground)
  background = cv2.multiply(1.0 - alpha, background)
  out_image = cv2.add(foreground, background)
  
  #Return statement
  return out_image

rgba = cv2.cvtColor(np.full((350, 530, 3), (255,255,0), np.dtype('uint8')), cv2.COLOR_RGB2RGBA)
rgba[:,:,3] = normalize_heat_map(heat_map_binary_thres_kernel_all)*255
cv2_imshow(rgba)
cv2_imshow(blend_heatmap('cage_background.png', heat_map_binary_thres_kernel_all, threshold = 0.80))

# Define function
def get_heat_map_binary_threshold(vid_array, mask, row_low = 50, row_high = 400, col_low = 100, col_high = 630):
  start_time = time.time()
  cap = cv2.VideoCapture(vid_array[0])

  ## Create a 2D array of type uint32
  frame_heat_map = np.zeros((row_high-row_low, col_high-col_low), np.dtype('uint32'))

  for vid in vid_array:
  ## Reading video frame by frame
    cap = cv2.VideoCapture(vid)

    success = True
    while success:
      success, image = cap.read()
      if success:

        ### convert each image to grayscale
        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[row_low:row_high, col_low:col_high]

        ### Threshold and mask
        gray_img[gray_img>150]  = 255
        gray_img[gray_img<=150] = 0
        cv2_imshow(gray_img)
        masked_image = (gray_img * (mask[row_low:row_high, col_low:col_high]/255)).astype('uint8')
        cv2_imshow(masked_image)
        ### Adjust the new created array
        frame_heat_map += (masked_image/255).astype('uint32')

  ##return to the matrix
  print("Total execution time for heat map:" , (time.time()-start_time), "seconds")
  return frame_heat_map/int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) 

get_heat_map_binary_threshold(['rabbit_video_3', 'rabbit_video_4'], mask = mask)